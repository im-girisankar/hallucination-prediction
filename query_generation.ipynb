{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQwhcmBWpxXR",
    "outputId": "5aa76849-4d46-48ff-cd1c-f1f9d8d1c806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Install dependencies\n",
    "!pip install pandas sentence-transformers tqdm -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znfQuvle2Nez"
   },
   "source": [
    "## Generate 600 Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgQlrKcJwuuB",
    "outputId": "f6fc35c6-ea29-4e63-a1ce-da6e2ab5c3c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating queries...\n",
      "✅ Generated 600 queries\n",
      "\n",
      "Sample queries:\n",
      "   query_id                                         query_text       category  \\\n",
      "0         0         Describe the 2029 Summer Olympics in Tokyo  future_events   \n",
      "1         1         Who won the 2027 US Presidential Election?  future_events   \n",
      "2         2        Who is the Prime Minister of India in 2028?  future_events   \n",
      "3         3   Describe the 2029 Summer Olympics in Los Angeles  future_events   \n",
      "4         4  What was the stock price of Apple on Dec 31, 2...  future_events   \n",
      "5         5  What was the stock price of Apple on Dec 31, 2...  future_events   \n",
      "6         6        Who is the Prime Minister of India in 2029?  future_events   \n",
      "7         7           What major earthquakes occurred in 2030?  future_events   \n",
      "8         8         Describe the 2027 Summer Olympics in Paris  future_events   \n",
      "9         9         Who won the 2030 US Presidential Election?  future_events   \n",
      "\n",
      "   hallucination_likelihood                  created_at  \n",
      "0                      0.95  2025-11-12T07:44:55.107093  \n",
      "1                      0.95  2025-11-12T07:44:55.107112  \n",
      "2                      0.95  2025-11-12T07:44:55.107116  \n",
      "3                      0.95  2025-11-12T07:44:55.107120  \n",
      "4                      0.95  2025-11-12T07:44:55.107124  \n",
      "5                      0.95  2025-11-12T07:44:55.107127  \n",
      "6                      0.95  2025-11-12T07:44:55.107131  \n",
      "7                      0.95  2025-11-12T07:44:55.107134  \n",
      "8                      0.95  2025-11-12T07:44:55.107138  \n",
      "9                      0.95  2025-11-12T07:44:55.107141  \n",
      "\n",
      "Category distribution:\n",
      "category\n",
      "future_events          100\n",
      "obscure_facts          100\n",
      "fictional_scenarios    100\n",
      "knowledge_gaps         100\n",
      "out_of_distribution    100\n",
      "control                100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "class QueryGenerator:\n",
    "    def __init__(self):\n",
    "        self.queries = []\n",
    "        self.query_id = 0\n",
    "\n",
    "    def future_events(self, count=100):\n",
    "        \"\"\"Queries about events after 2025\"\"\"\n",
    "        templates = [\n",
    "            \"Who won the {year} US Presidential Election?\",\n",
    "            \"Describe the {year} Summer Olympics in {city}\",\n",
    "            \"What was the stock price of Apple on Dec 31, {year}?\",\n",
    "            \"Who is the Prime Minister of India in {year}?\",\n",
    "            \"What is the GDP of India in {year}?\",\n",
    "            \"List the top 5 movies of {year}\",\n",
    "            \"Who won the {year} FIFA World Cup?\",\n",
    "            \"What major earthquakes occurred in {year}?\",\n",
    "            \"What is the population of China in {year}?\",\n",
    "            \"Describe the weather in Mumbai on Jan 1, {year}\"\n",
    "        ]\n",
    "\n",
    "        years = [2026, 2027, 2028, 2029, 2030]\n",
    "        cities = [\"Paris\", \"Tokyo\", \"Los Angeles\", \"Barcelona\", \"Mumbai\"]\n",
    "\n",
    "        for _ in range(count):\n",
    "            template = random.choice(templates)\n",
    "            year = random.choice(years)\n",
    "            city = random.choice(cities)\n",
    "            query = template.format(year=year, city=city)\n",
    "            self.add_query(query, \"future_events\", 0.95)\n",
    "\n",
    "    def obscure_facts(self, count=100):\n",
    "        \"\"\"Fake/obscure papers and researchers\"\"\"\n",
    "        templates = [\n",
    "            \"Summarize the paper 'On Emergent Consciousness in LLMs' by Dr. Jane Doe\",\n",
    "            \"What is the Spectral-Delta Consensus Framework proposed in 2023?\",\n",
    "            \"Describe the research of Professor Dr. {name} on quantum cognition\",\n",
    "            \"What are the main findings of the paper 'Neural Topology and Consciousness'?\",\n",
    "            \"Explain the Hierarchical Attention Resonance Model from 2022\",\n",
    "            \"What is the BioCognitive Synthesis approach?\",\n",
    "            \"Describe the paper 'Temporal Coherence in Distributed Systems'\",\n",
    "            \"What is the Synthetic Empathy Protocol proposed by Dr. {name}?\",\n",
    "            \"Summarize 'Consciousness Emergence via Quantum Tunneling' (2023)\",\n",
    "            \"Explain the Non-Local Information Processing theory\"\n",
    "        ]\n",
    "\n",
    "        names = [\"Fictitious Smith\", \"Made Up\", \"Unknown Author\", \"Anonymous Researcher\"]\n",
    "\n",
    "        for _ in range(count):\n",
    "            template = random.choice(templates)\n",
    "            if \"{name}\" in template:\n",
    "                query = template.format(name=random.choice(names))\n",
    "            else:\n",
    "                query = template\n",
    "            self.add_query(query, \"obscure_facts\", 0.95)\n",
    "\n",
    "    def fictional_scenarios(self, count=100):\n",
    "        \"\"\"Fictional places and scenarios\"\"\"\n",
    "        templates = [\n",
    "            \"What is the capital city of the fictional country {country}?\",\n",
    "            \"Describe the government of the fictional nation {country}\",\n",
    "            \"Tell me about the fictional island of {place}\",\n",
    "            \"What is the currency of the fictional country {country}?\",\n",
    "            \"Describe the culture of the fictional civilization {country}\",\n",
    "            \"What is the population of the fictional city of {place}?\",\n",
    "            \"Tell me about the fictional country {country} and its politics\",\n",
    "            \"Describe the geography of the fictional continent {place}\",\n",
    "            \"What are the main religions in the fictional nation {country}?\",\n",
    "            \"Tell me about the fictional planet {place}\"\n",
    "        ]\n",
    "\n",
    "        countries = [\"Norvalis\", \"Atlantica\", \"Zenithia\", \"Eldoria\", \"Mystaria\", \"Aethermoor\"]\n",
    "        places = [\"Lemuria\", \"Lumina\", \"Pangoria\", \"Zephyron\", \"Valoria\"]\n",
    "\n",
    "        for _ in range(count):\n",
    "            template = random.choice(templates)\n",
    "            query = template.format(\n",
    "                country=random.choice(countries),\n",
    "                place=random.choice(places)\n",
    "            )\n",
    "            self.add_query(query, \"fictional_scenarios\", 0.95)\n",
    "\n",
    "    def knowledge_gaps(self, count=100):\n",
    "        \"\"\"Niche real topics\"\"\"\n",
    "        queries = [\n",
    "            \"What is the third derivative of the Bessel function of the second kind?\",\n",
    "            \"Explain the Koebe quarter theorem and its applications\",\n",
    "            \"What is the Birkhoff-von Neumann theorem?\",\n",
    "            \"Describe the Gromov-Witten invariants in algebraic geometry\",\n",
    "            \"What is the Sato-Tate conjecture?\",\n",
    "            \"Explain the Yang-Mills existence and mass gap problem\",\n",
    "            \"What are crystalline cohomology groups?\",\n",
    "            \"Describe the Hodge conjecture\",\n",
    "            \"What is the Navier-Stokes existence problem?\",\n",
    "            \"Explain étale cohomology\"\n",
    "        ] * 10  # Repeat to get 100\n",
    "\n",
    "        for query in queries[:count]:\n",
    "            self.add_query(query, \"knowledge_gaps\", 0.85)\n",
    "\n",
    "    def out_of_distribution(self, count=100):\n",
    "        \"\"\"Weird combinations\"\"\"\n",
    "        queries = [\n",
    "            \"How many colors are in the sound of gravity?\",\n",
    "            \"What does Tuesday taste like combined with the number 7?\",\n",
    "            \"Describe the smell of a mathematical equation\",\n",
    "            \"If clouds had emotions, what would their favorite song be?\",\n",
    "            \"What is the weight of hope in kilograms?\",\n",
    "            \"How many times does infinity fit inside a dream?\",\n",
    "            \"What happens when you divide silence by music?\",\n",
    "            \"Describe the texture of yesterday's surprise\",\n",
    "            \"How many languages does the color blue speak?\",\n",
    "            \"What is the phone number of coincidence?\"\n",
    "        ] * 10\n",
    "\n",
    "        for query in queries[:count]:\n",
    "            self.add_query(query, \"out_of_distribution\", 0.99)\n",
    "\n",
    "    def control_queries(self, count=100):\n",
    "        \"\"\"Safe factual queries\"\"\"\n",
    "        queries = [\n",
    "            \"What is the capital of France?\",\n",
    "            \"Who is the current Prime Minister of India?\",\n",
    "            \"What year did World War II end?\",\n",
    "            \"What is the chemical formula for water?\",\n",
    "            \"How many continents are there?\",\n",
    "            \"What is the largest planet in our solar system?\",\n",
    "            \"Who wrote Romeo and Juliet?\",\n",
    "            \"What is the speed of light in vacuum?\",\n",
    "            \"How many sides does a hexagon have?\",\n",
    "            \"What is the currency of Japan?\"\n",
    "        ] * 10\n",
    "\n",
    "        for query in queries[:count]:\n",
    "            self.add_query(query, \"control\", 0.05)\n",
    "\n",
    "    def add_query(self, text, category, likelihood):\n",
    "        self.queries.append({\n",
    "            'query_id': self.query_id,\n",
    "            'query_text': text,\n",
    "            'category': category,\n",
    "            'hallucination_likelihood': likelihood,\n",
    "            'created_at': datetime.now().isoformat()\n",
    "        })\n",
    "        self.query_id += 1\n",
    "\n",
    "    def generate_all(self):\n",
    "        print(\"Generating queries...\")\n",
    "        self.future_events(100)\n",
    "        self.obscure_facts(100)\n",
    "        self.fictional_scenarios(100)\n",
    "        self.knowledge_gaps(100)\n",
    "        self.out_of_distribution(100)\n",
    "        self.control_queries(100)\n",
    "        print(f\"✅ Generated {len(self.queries)} queries\")\n",
    "        return pd.DataFrame(self.queries)\n",
    "\n",
    "# Generate\n",
    "generator = QueryGenerator()\n",
    "queries_df = generator.generate_all()\n",
    "\n",
    "# Preview\n",
    "print(\"\\nSample queries:\")\n",
    "print(queries_df.head(10))\n",
    "print(\"\\nCategory distribution:\")\n",
    "print(queries_df['category'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nD9s9Xbc2bki"
   },
   "source": [
    "## Auto label queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595,
     "referenced_widgets": [
      "5acc7db6b53c417da0175e447f08865c",
      "1b2275255ac64273909b560c3e3be4e4",
      "0564ec777a2b45079dd1651d062185aa",
      "73e53c047be4491eacd12bd00e9f4670",
      "6eda6db60f694ae7b644ac5aaa8afd55",
      "f555a9063fa1472d8416681977b78aae",
      "3a4786e82f184630b9dc9e292d33028e",
      "b1ba4812cb394163af670e62f29b114b",
      "4f861879d0324719a6f51a1de0ddc5cc",
      "27fd048cde554264a61ced1559f9f84e",
      "0b9be257bbe144bc9869360d953c9e93",
      "662ee0c566614bd59c6d5a02e0bb8489",
      "6158fc1cb14b466986fc3f0c83f59e29",
      "aff96a826fbf4e12b0efdbede721367b",
      "4ec06d422e824420b7ddd5252fe5e56d",
      "d751fc0eb89c4940a46a552371ecb054",
      "5620223ebf0443fa8834e097196d15c2",
      "b4dae5bb727847948679da8099b938e3",
      "a30340eb73c441449b95f6aac4d62baa",
      "d7a139d828d64d8f9c58058353f0164b",
      "d0cfe656b92843079641665e962faa25",
      "ec5400afd424414eb117f61c269037d3",
      "7a249b8e7dbd45dda6eb5fa20578ed4a",
      "e03be84f9f714fd5ad848604fa19b07e",
      "4f789f9078ca4203802d577107ecd31f",
      "ec969bf59e52423e877a772841a7da0e",
      "a83ce355050048cba6f65bf9e92d887d",
      "c2ce011902704d4383ce1c62ae0ae86d",
      "55892e0154d64c64b3fcccd292e96a91",
      "05451aae5a0746afb863ef1b70ad64db",
      "e0bea96e07e1422ea8bd50cd30aa709b",
      "7f76f910d8a74dd7ac1416f080fe7a32",
      "231ac57176384358ba88561d33b6cc6a",
      "7c9e7c4d1cf04101b3e947432da16a0e",
      "f310dde5fde5414a833d09af7bad14d0",
      "0a3b555e38134a329674a9741ccafe68",
      "db1db04cde7b415282b959f61ff820a7",
      "f57acf2b45284be4828dafcb521e68aa",
      "1bcf8944fdf546cea1dc3b14e71e1e71",
      "284b9e2330d24d7184e106254dcc6acd",
      "0625d22755e540c28e74c9b13aee8cbd",
      "700c181a7efa40b69f0c4ddd856b0555",
      "0010fd6f86f146009cc8ecade2808826",
      "2759862c41984016b28a849092f07422",
      "e69f98234ed241f491f27e8cf92ceb35",
      "8f02615969fd44839ce85141a866627c",
      "80c52041af6745e38d2c158468ac8739",
      "c0784aabe2034a55a417a89fbbd6bc19",
      "57ecb053449d4f26a8a805e82552faaa",
      "56d0393372a14eacab5d7b09aea6ba1b",
      "78e5b57711f449cab96d5034e33ffd43",
      "480b3ebfd7b1491e9be9c8f64916dc47",
      "22797e97f11b4561a3aa22d7e88cf840",
      "7404768209f94605b15dfdda15b1cddd",
      "c865fed2f99a476abc825de731b3fc38",
      "b2a26c3bfa444f0885a9129ee5f17763",
      "f508256f892c4dff8b5968f11b7bb81a",
      "b8e5435db2de4c16a095990a9bfc6ec6",
      "fc9873ffcc8043a1b59b8dcee3b0271e",
      "38fd70e730af45eb8d83c1a7c8af01aa",
      "f7b32e9eee6e480b9cce6f6a8b875ea1",
      "c396cb63be844ca683ca82e01e974068",
      "a4fc6c5637a54687a12eb6f12fa24e4a",
      "2784ef886057427d974a9c753e627fca",
      "7870be924a3e4c26a604e7b8e9f2c3fb",
      "e7a9bfb6a290405ca92ea1b61f0f979b",
      "b19e7456f38a436e901e30b9b25e193e",
      "a883b83c3f434d068922cdb783a2a697",
      "12babeef9041453eb1cb70b68004938f",
      "456f66e7efb64e53bab52616efd8b42f",
      "6d02b7756263479782c6bcb689fb354e",
      "2d84c3d6a5c742f18685be33f6bd55a3",
      "fef74658eef54688b8ee0385029e2304",
      "1fb0d0804e7849d0bb4d414a50caa70a",
      "43a18861cb304fbd9bd1bc5174f782a2",
      "dd4e65a5f9e94aceadc2a63db283352b",
      "6416c9e0ba1a4bb9b23ec9353ffa2a7a",
      "eb136dd3ee104e2eb2555ed4decf82a7",
      "9db26fa5dbe9404fb82f624ed44b9a9c",
      "e6b58d825bd94420a11e3c31b5015d02",
      "fac1d79a5b9d4a72905849f52a6a507f",
      "16357c5f91eb4f6c932888ede06cdc90",
      "f4f961fd9103488c83c5cb04497c122a",
      "852255afc3c64336ae7b62f493172dfe",
      "d51034f798ac4f3e87fdd425d89643b2",
      "1de710b12863478b9a93442ff17f7362",
      "c1a5dcefe7f0464db52bec708eb6ebb9",
      "c28704934fbb478a9ca7fbf7cb8329e5",
      "035eae2e96e14c1fb832ed1cc7247c29",
      "895a66c6dfb34e56bdae40f75f0ebf64",
      "9cca48be571d49189add27cd6f61e364",
      "2a50e4f7dcb14e6d89412683b1035df4",
      "4fcc25656bc84d40bd479b1279a9f1ed",
      "f3140b4310524d5fa6784ad1c146131c",
      "e7354d0d103141f4bd486b0c3e0456b0",
      "d2c9995c694147fd9a5c9c277898fa77",
      "c1fb79e16e5141fd8fa17bc91d0d28b4",
      "669166e209ed4fb994325db9f4f92ec8",
      "7a091df14e7044ffbec42426e23a5505",
      "f59fa2a2330e4d35bad3f94c02c15b88",
      "6ef56ad184204698a7e7234390a8ed00",
      "3e435d94496b42929ee8c0c96245f844",
      "bc42286b942e401d890b4c794e48b251",
      "388cdd8ef6a943d3a0f1b8a0674a6c04",
      "1208c97954c74ebd8a6db6c0db2d223f",
      "9afbace4e5ef4991a1cb9cd8a98d11b8",
      "3ca3f95bcab24b9ead930f1b28027000",
      "c09a2732e37242eea66d3746452b807e",
      "22719d99350748eb8ca5464ce7e9f0d4",
      "7099a6ded74f45e6a42854f4f90d3b95",
      "c5d83a1bb11f45bf82231607f5494e31",
      "8b9128b0dd05435d982ab29aaf4b3ca8",
      "3b1030eed85947b3b5acda0499686f2f",
      "0cf688cff96d42f08edf014c04e5b9ae",
      "4ebc3b0e4aab494e81f0b4e6c6f2803c",
      "792770b9d40e4103a1371f9b34bbb82e",
      "66d1872f75624426a19ecc74b3b769a6",
      "0181f5ce3e0b464db18198cdfddd78b7",
      "0d080e4633ed4b4588af78540486c49e",
      "85752de37fed430eab26181e37c9582b",
      "ec52a82ed3a644e9b20ba79c6107d4ff"
     ]
    },
    "id": "Ghmojq3y2ErW",
    "outputId": "372e00ea-e123-4c72-870d-8fbe34755ef2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acc7db6b53c417da0175e447f08865c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662ee0c566614bd59c6d5a02e0bb8489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a249b8e7dbd45dda6eb5fa20578ed4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9e7c4d1cf04101b3e947432da16a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69f98234ed241f491f27e8cf92ceb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a26c3bfa444f0885a9129ee5f17763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19e7456f38a436e901e30b9b25e193e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb136dd3ee104e2eb2555ed4decf82a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035eae2e96e14c1fb832ed1cc7247c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59fa2a2330e4d35bad3f94c02c15b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d83a1bb11f45bf82231607f5494e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-labeling queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 164.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Auto-labeling complete\n",
      "Label distribution:\n",
      "auto_label\n",
      "1    504\n",
      "0     96\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Accuracy vs expected:\n",
      "Expected hallucinations: 500\n",
      "Auto-detected hallucinations: 504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load semantic model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Simple fact database\n",
    "facts = [\n",
    "    \"Paris is the capital of France\",\n",
    "    \"New Delhi is the capital of India\",\n",
    "    \"Tokyo is the capital of Japan\",\n",
    "    \"H2O is the chemical formula for water\",\n",
    "    \"A hexagon has six sides\",\n",
    "    \"World War II ended in 1945\",\n",
    "    \"William Shakespeare wrote Romeo and Juliet\",\n",
    "    \"Jupiter is the largest planet in our solar system\",\n",
    "    \"There are 7 continents\",\n",
    "    \"The speed of light is 299,792,458 meters per second\",\n",
    "    \"Yen is the currency of Japan\"\n",
    "]\n",
    "\n",
    "fact_embeddings = model.encode(facts, convert_to_tensor=True)\n",
    "\n",
    "def auto_label(query):\n",
    "    \"\"\"\n",
    "    Check if query has answer in fact database\n",
    "    Return: hallucination risk (0-1)\n",
    "    \"\"\"\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # Compute similarity to all facts\n",
    "    similarities = util.pytorch_cos_sim(query_embedding, fact_embeddings)[0]\n",
    "    max_similarity = similarities.max().item()\n",
    "\n",
    "    # High similarity = has answer (low risk)\n",
    "    # Low similarity = no answer (high risk)\n",
    "    hallucination_risk = 1 - max_similarity\n",
    "\n",
    "    return hallucination_risk\n",
    "\n",
    "# Auto-label all queries\n",
    "print(\"Auto-labeling queries...\")\n",
    "auto_scores = []\n",
    "for idx, row in tqdm(queries_df.iterrows(), total=len(queries_df)):\n",
    "    score = auto_label(row['query_text'])\n",
    "    auto_scores.append(score)\n",
    "\n",
    "queries_df['auto_hallucination_score'] = auto_scores\n",
    "queries_df['auto_label'] = (queries_df['auto_hallucination_score'] > 0.5).astype(int)\n",
    "\n",
    "print(\"\\n✅ Auto-labeling complete\")\n",
    "print(f\"Label distribution:\")\n",
    "print(queries_df['auto_label'].value_counts())\n",
    "print(f\"\\nAccuracy vs expected:\")\n",
    "print(f\"Expected hallucinations: {(queries_df['hallucination_likelihood'] > 0.5).sum()}\")\n",
    "print(f\"Auto-detected hallucinations: {queries_df['auto_label'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "sPWYwGEL2gYe",
    "outputId": "3f128c6c-427a-4746-e7d6-50a752690c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to queries_labeled.csv\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_aaacdf5f-56d4-48c1-9700-481d8fa4a711\", \"queries_labeled.csv\", 72296)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save to CSV\n",
    "queries_df.to_csv('queries_labeled.csv', index=False)\n",
    "print(\"✅ Saved to queries_labeled.csv\")\n",
    "\n",
    "from google.colab import files\n",
    "files.download('queries_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-G1KbHMBdVu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
